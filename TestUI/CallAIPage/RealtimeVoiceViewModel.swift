//
//  RealtimeVoiceViewModel.swift
//  SalmaAI
//
//  Created by Soubani on 03/10/2025.
//  FIXED VERSION - Updated for better consistency
//

import Foundation
import AVFoundation
import WebRTC
import SwiftUI
import UIKit

struct ChatMessage: Identifiable, Equatable, Hashable {
    let id: String
    let text: String
    let isUser: Bool
    let timestamp: Date

    init(id: String = UUID().uuidString,
         text: String,
         isUser: Bool,
         timestamp: Date = Date()) {
        self.id = id
        self.text = text
        self.isUser = isUser
        self.timestamp = timestamp
    }
}

struct CliQTransferData {
    let page: String
    let amount: String?
    let phone: String?
    let alias: String?
    
    init(page: String, amount: String? = nil, phone: String? = nil, alias: String? = nil) {
        self.page = page
        self.amount = amount
        self.phone = phone
        self.alias = alias
    }
}

@MainActor
final class RealtimeVoiceViewModel: NSObject, ObservableObject {

    // MARK: - Published (UI)
    @Published var bands: [CGFloat] = Array(repeating: 0.05, count: 20)
    @Published var isConnected: Bool = false
    @Published var messages: [ChatMessage] = []
    @Published var lastReply: String?
    @Published var navigationTarget: String? = nil  // âœ… Ù„Ù„ØªÙ†Ù‚Ù„ Ù„Ù„ØµÙØ­Ø§Øª
    @Published var pendingNavigation: String? = nil  // âœ… Ù„Ù„ØªÙ†Ù‚Ù„ Ø§Ù„Ù…Ø¹Ù„Ù‚ Ø¨Ø¹Ø¯ Ø§Ù„Ø§ØªØµØ§Ù„
    
    // MARK: - CliQ Transfer Parameters
    @Published var cliqAmount: String? = nil
    @Published var cliqPhoneNumber: String? = nil
    @Published var cliqAlias: String? = nil
    
    // MARK: - Session Management
    var sessionID: String?  // âœ… Ù„Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… ÙÙŠ polling
    
    // MARK: - Navigation detection
    private var lastAIText: String = ""
    private var navigationTimer: Timer?
    private let backendURL = "http://34.132.130.63:8000"
    private var pendingFunctionCallArgs: [String: String] = [:] // Ù„ØªØ¬Ù…ÙŠØ¹ function arguments

    // MARK: - WebRTC
    private var pcStored: RTCPeerConnection?
    private let factory = RTCPeerConnectionFactory()

    // MARK: - DataChannel Ù„Ù„Ø£Ø­Ø¯Ø§Ø«
    private var eventsDC: RTCDataChannel?

    // MARK: - Audio Metering (Stats)
    private var statsTimer: Timer?
    private var emaInbound: Double = 0.0  // Ù…Ø³ØªÙˆÙ‰ ØµÙˆØª AI (inbound)
    private var emaOutbound: Double = 0.0 // ØµÙˆØª Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… (outbound)
    private let emaAlpha: Double = 0.35   // ØªÙ†Ø¹ÙŠÙ… (0..1)ØŒ Ø§Ù„Ø£ÙƒØ¨Ø± Ø£Ø³Ø±Ø¹ Ø§Ø³ØªØ¬Ø§Ø¨Ø©
    private let silenceThreshold: Double = 0.015 // ÙÙ„ØªØ± Ø¶Ø¬ÙŠØ¬ Ù…Ù†Ø®ÙØ¶

    // MARK: - Session flags
    private var isScreenCaptured: Bool { UIScreen.main.isCaptured }

    override init() {
        super.init()
        // Ø±Ø§Ù‚Ø¨ ØªØºÙŠÙŠØ± Ø­Ø§Ù„Ø© ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø´Ø§Ø´Ø© Ù„Ø¥Ø¹Ø§Ø¯Ø© ØªÙ‡ÙŠØ¦Ø© Ø§Ù„ØµÙˆØª
        NotificationCenter.default.addObserver(
            forName: UIScreen.capturedDidChangeNotification,
            object: nil, queue: .main
        ) { [weak self] _ in
            Task { @MainActor in
                try? self?.reconfigureAudioSessionForCaptureChange()
            }
        }
    }

    deinit {
        NotificationCenter.default.removeObserver(self)
    }

    // MARK: - Mic permission (iOS)
    private func ensureMicPermission() async throws {
        let current = AVAudioSession.sharedInstance().recordPermission
        if current == .granted { return }
        try await withCheckedThrowingContinuation { cont in
            AVAudioSession.sharedInstance().requestRecordPermission { granted in
                if granted { cont.resume() }
                else {
                    cont.resume(throwing: NSError(
                        domain: "RealtimeVoice",
                        code: -1,
                        userInfo: [NSLocalizedDescriptionKey: "Microphone permission denied"]
                    ))
                }
            }
        }
    }

    // MARK: - Connect
    func connectToRealtime() async {
        do {
            try await ensureMicPermission()
            try configureAudioSession() // ØªÙ‡ÙŠØ¦Ø© Ø£ÙˆÙ„ÙŠØ© (ØªØ³Ù…Ø­ Ø¨Ø§Ù„Ù…Ø²Ø¬ ÙˆØ§Ù„ØªØ³Ø¬ÙŠÙ„)

            // 1) Ø§Ø­ØµÙ„ Ø¹Ù„Ù‰ client_secret Ù…Ù† Ø§Ù„Ø³ÙŠØ±ÙØ± (Ø§Ù„ØµÙˆØª Ù…Ù‚ÙÙˆÙ„ cedar Ø¨Ø§Ù„Ø³ÙŠØ±ÙØ±)
            let tokenURL = URL(string: "http://34.132.130.63:8000/v1/realtime/token")!
            var tokenReq = URLRequest(url: tokenURL)
            tokenReq.httpMethod = "POST"

            let (tokData, tokResp) = try await URLSession.shared.data(for: tokenReq)
            guard let http = tokResp as? HTTPURLResponse, http.statusCode < 300 else {
                let body = String(data: tokData, encoding: .utf8) ?? ""
                throw NSError(domain: "RealtimeVoice", code: -10,
                              userInfo: [NSLocalizedDescriptionKey: "Token HTTP error: \((tokResp as? HTTPURLResponse)?.statusCode ?? -1)\n\(body)"])
            }
            guard
                let json = try JSONSerialization.jsonObject(with: tokData) as? [String: Any],
                let clientSecret = (json["client_secret"] as? [String: Any])?["value"] as? String,
                !clientSecret.isEmpty
            else {
                throw NSError(domain: "RealtimeVoice", code: -11,
                              userInfo: [NSLocalizedDescriptionKey: "client_secret missing/empty"])
            }
            print("ğŸŸ¢ clientSecret length:", clientSecret.count)

            // 2) PeerConnection
            let config = RTCConfiguration()
            config.sdpSemantics = .unifiedPlan
            let constraints = RTCMediaConstraints(mandatoryConstraints: nil, optionalConstraints: nil)

            guard let pc = factory.peerConnection(with: config,
                                                  constraints: constraints,
                                                  delegate: self) else {
                throw NSError(domain: "RealtimeVoice", code: -12,
                              userInfo: [NSLocalizedDescriptionKey: "Failed to create RTCPeerConnection"])
            }
            self.pcStored = pc

            // 2.5) DataChannel
            let dcConfig = RTCDataChannelConfiguration()
            dcConfig.isOrdered = true
            let eventsDC = pc.dataChannel(forLabel: "oai-events", configuration: dcConfig)
            eventsDC?.delegate = self
            self.eventsDC = eventsDC

            // 3) Add mic track (Ø¥Ø±Ø³Ø§Ù„ ØµÙˆØª Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…)
            let audioSource = factory.audioSource(with: nil)
            let audioTrack = factory.audioTrack(with: audioSource, trackId: "mic")
            pc.add(audioTrack, streamIds: ["local_stream"])

            // Ensure send/recv
            let tx: RTCRtpTransceiver
            if let existing = pc.transceivers.first(where: { $0.mediaType == .audio }) {
                tx = existing
            } else {
                guard let created = pc.addTransceiver(of: .audio) else {
                    throw NSError(domain: "RealtimeVoice", code: -15,
                                  userInfo: [NSLocalizedDescriptionKey: "Failed to add audio transceiver"])
                }
                tx = created
            }
            var txErr: NSError?
            _ = tx.setDirection(.sendRecv, error: &txErr)
            if let e = txErr { print("âš ï¸ setDirection error:", e.localizedDescription) }

            // 4) Offer + Local SDP
            let offerConstraints = RTCMediaConstraints(
                mandatoryConstraints: ["OfferToReceiveAudio":"true"],
                optionalConstraints: nil
            )
            let offer = try await pc.offer(for: offerConstraints)
            try await pc.setLocalDescription(offer)

            // 5) ICE
            try await waitForIceGatheringComplete(using: pc, timeout: 8.0)
            guard let localSDP = pc.localDescription?.sdp, !localSDP.isEmpty else {
                throw NSError(domain: "RealtimeVoice", code: -13,
                              userInfo: [NSLocalizedDescriptionKey: "Local SDP empty"])
            }

            // 6) Send SDP to OpenAI Realtime
            var req = URLRequest(url: URL(string: "https://api.openai.com/v1/realtime?model=gpt-realtime")!)
            req.httpMethod = "POST"
            req.setValue("Bearer \(clientSecret)", forHTTPHeaderField: "Authorization")
            req.setValue("realtime=v1", forHTTPHeaderField: "OpenAI-Beta")
            req.setValue("application/sdp", forHTTPHeaderField: "Content-Type")
            req.setValue("application/sdp", forHTTPHeaderField: "Accept")
            req.httpBody = localSDP.data(using: .utf8)

            let (ansData, ansResp) = try await URLSession.shared.data(for: req)
            if let http = ansResp as? HTTPURLResponse, http.statusCode >= 300 {
                let body = String(data: ansData, encoding: .utf8) ?? ""
                throw NSError(domain: "OpenAIRealtime", code: http.statusCode,
                              userInfo: [NSLocalizedDescriptionKey: "HTTP \(http.statusCode): \(body)"])
            }

            guard let sdpAnswer = String(data: ansData, encoding: .utf8),
                  sdpAnswer.contains("a=ice-ufrag") else {
                let raw = String(data: ansData, encoding: .utf8) ?? ""
                throw NSError(domain: "OpenAIRealtime", code: -14,
                              userInfo: [NSLocalizedDescriptionKey: "No SDP answer. Got: \(raw)"])
            }

            let answer = RTCSessionDescription(type: .answer, sdp: sdpAnswer)
            try await pc.setRemoteDescription(answer)

            // âœ… Start stats metering
            startStatsMetering(on: pc)
            
            // âœ… Set session ID
            let newSessionID = UUID().uuidString
            self.sessionID = newSessionID
            print("ğŸ“± Session ID: \(newSessionID)")

            DispatchQueue.main.async {
                self.isConnected = true
                self.messages.append(ChatMessage(text: "âœ… Connected to Realtime Voice", isUser: false))
                self.startNavigationPolling()  // âœ… Ø§Ø¨Ø¯Ø£ polling
                
                // Ø§Ø³ØªØ¹Ø§Ø¯Ø© Ø£ÙŠ pending navigation
                if let pendingNav = self.pendingNavigation {
                    print("ğŸ”” Restoring pending navigation: \(pendingNav)")
                    self.navigationTarget = pendingNav
                    self.pendingNavigation = nil
                }
            }
            print("âœ… Connected to Realtime Voice")

        } catch {
            DispatchQueue.main.async {
                self.messages.append(ChatMessage(text: "âŒ \(error.localizedDescription)", isUser: false))
                self.isConnected = false
                self.resetBandsToSilence()
            }
            print("âŒ Realtime connect error:", error.localizedDescription)
            disconnect()
        }
    }

    func disconnect() {
        stopStatsMetering()
        stopNavigationPolling()  // âœ… Ø£ÙˆÙ‚Ù polling
        
        // Ø­ÙØ¸ Ø£ÙŠ pending navigation Ù‚Ø¨Ù„ Ø§Ù„Ø§Ù†ÙØµØ§Ù„
        if let navTarget = navigationTarget {
            pendingNavigation = navTarget
            print("ğŸ“¦ Saved pending navigation: \(navTarget)")
        }
        
        pcStored?.close()
        pcStored = nil
        isConnected = false
        resetBandsToSilence()
        pendingFunctionCallArgs.removeAll() // âœ… Ù†Ø¸Ù function call args
        navigationTarget = nil // âœ… Ø§Ù…Ø³Ø­ navigationTarget Ø¹Ù†Ø¯ Ø§Ù„Ø§Ù†ÙØµØ§Ù„
        print("ğŸ›‘ Disconnected from Realtime")
    }
    
    // MARK: - Navigation Polling
    
    func startNavigationPolling() {
        guard navigationTimer == nil else { return }
        
        navigationTimer = Timer.scheduledTimer(withTimeInterval: 1.0, repeats: true) { [weak self] _ in
            Task { @MainActor in
                await self?.checkForNavigationCommand()
            }
        }
        print("âœ… Started navigation polling")
    }
    
    func stopNavigationPolling() {
        navigationTimer?.invalidate()
        navigationTimer = nil
        print("ğŸ›‘ Stopped navigation polling")
    }
    
    private func checkForNavigationCommand() async {
        guard let sessionID = sessionID else { return }
        
        let url = URL(string: "\(backendURL)/v1/navigation/check/\(sessionID)")!
        
        do {
            let (data, _) = try await URLSession.shared.data(from: url)
            
            if let json = try JSONSerialization.jsonObject(with: data) as? [String: Any],
               let hasNav = json["has_navigation"] as? Bool,
               hasNav == true,
               let page = json["page"] as? String {
                
                print("ğŸ¯ Navigation command received: \(page)")
                DispatchQueue.main.async {
                    self.navigationTarget = page
                }
            }
        } catch {
            // Silent fail - don't spam console
        }
    }

    // MARK: - Audio Session

    /// Ø¥Ø¹Ø¯Ø§Ø¯ ØµØ¯ÙŠÙ‚ Ù„ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø´Ø§Ø´Ø©: ÙŠÙ…Ø²Ø¬ Ù…Ø¹ Ø§Ù„Ø¢Ø®Ø±ÙŠÙ† ÙˆÙŠØªØ±Ùƒ ReplayKit ÙŠÙ„ØªÙ‚Ø· ØµÙˆØª Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ØŒ
    /// ÙˆÙŠØ³ØªÙ…Ø± Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù…Ø§ÙŠÙƒ Ù„Ù„Ù…ÙƒØ§Ù„Ù…Ø©.
    private func configureAudioSession() throws {
        let rtc = RTCAudioSession.sharedInstance()
        let av  = AVAudioSession.sharedInstance()

        rtc.lockForConfiguration()
        defer { rtc.unlockForConfiguration() }

        var cfg = RTCAudioSessionConfiguration.webRTC()
        cfg.category = AVAudioSession.Category.playAndRecord.rawValue
        cfg.mode = AVAudioSession.Mode.voiceChat.rawValue

        // Ù…Ù‡Ù…: mixWithOthers ÙŠØ³Ù…Ø­ Ù„ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø´Ø§Ø´Ø© ÙŠØ£Ø®Ø° Ø§Ù„ØµÙˆØª Ø¨Ø¯ÙˆÙ† Ù‚Ø·Ø¹ Ø¬Ù„Ø³Ø© Ø§Ù„ØªØ·Ø¨ÙŠÙ‚
        // defaultToSpeaker Ù„Ù„Ø®Ø±ÙˆØ¬ Ù…Ù† Ø³Ù…Ø§Ø¹Ø© Ø§Ù„Ø¬Ù‡Ø§Ø²ØŒ allowBluetooth/A2DP Ù„Ù„Ø³Ù…Ø§Ø¹Ø§Øª
        let opts: AVAudioSession.CategoryOptions = [
            .mixWithOthers,
            .defaultToSpeaker,
            .allowBluetooth,
            .allowBluetoothA2DP
        ]
        cfg.categoryOptions = opts

        try rtc.setConfiguration(cfg)
        try rtc.setActive(true)

        // Ø£Ø«Ù†Ø§Ø¡ ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø´Ø§Ø´Ø©ØŒ Ù„Ø§ ØªØ¬Ø¨Ø± Ø§Ù„Ø¥Ø®Ø±Ø§Ø¬ Ø¹Ù„Ù‰ Ø§Ù„Ø³Ù…Ø§Ø¹Ø© â€” Ø®Ù„Ù‘ÙŠ iOS ÙŠØ®ØªØ§Ø± Ø§Ù„Ù…Ø³Ø§Ø± Ø§Ù„Ù…Ù†Ø§Ø³Ø¨
        if !isScreenCaptured {
            try? av.overrideOutputAudioPort(.speaker)
        } else {
            try? av.overrideOutputAudioPort(.none)
        }

        // Ø¹ÙŠÙ‘Ù† Ù…Ø¹Ø¯Ù„ Ø§Ù„Ø¹ÙŠÙ‘Ù†Ø© ÙˆÙ…Ø¯Ø© Ø§Ù„Ø¨ÙØ± Ù„Ø£Ø¯Ø§Ø¡ Ø£ÙØ¶Ù„ Ù…Ø¹ WebRTC + ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø´Ø§Ø´Ø©
        try? av.setPreferredSampleRate(48000)
        try? av.setPreferredIOBufferDuration(0.01)
    }

    /// Ø¥Ø¹Ø§Ø¯Ø© ØªÙ‡ÙŠØ¦Ø© Ø³Ø±ÙŠØ¹Ø© Ø¹Ù†Ø¯ Ø¨Ø¯Ø¡/Ø¥ÙŠÙ‚Ø§Ù ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø´Ø§Ø´Ø©
    private func reconfigureAudioSessionForCaptureChange() throws {
        let av = AVAudioSession.sharedInstance()
        if isScreenCaptured {
            // Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„ØªØ³Ø¬ÙŠÙ„: Ù„Ø§ Ø¥Ø¬Ø¨Ø§Ø± Ø¹Ù„Ù‰ Ø§Ù„Ø³Ù…Ø§Ø¹Ø©ØŒ Ø£Ø¨Ù‚Ù Ø§Ù„Ù…Ø²Ø¬ Ù…ÙØ¹Ù‘Ù„
            try? av.overrideOutputAudioPort(.none)
        } else {
            // Ø±Ø¬Ù‘Ø¹ Ù„Ù„Ø³Ù…Ø§Ø¹Ø© Ø¨Ø¹Ø¯ Ø§Ù„Ø§Ù†ØªÙ‡Ø§Ø¡ (Ù„Ùˆ ØªØ­Ø¨ Ø§Ù„Ø³Ù„ÙˆÙƒ Ù‡Ø°Ø§)
            try? av.overrideOutputAudioPort(.speaker)
        }

        // Ø£Ø¹Ø¯ ØªÙ‡ÙŠØ¦Ø© RTCAudioSession Ø¨Ù†ÙØ³ Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ù„Ø¶Ù…Ø§Ù† Ø§Ù„Ø«Ø¨Ø§Øª
        let rtc = RTCAudioSession.sharedInstance()
        rtc.lockForConfiguration()
        defer { rtc.unlockForConfiguration() }
        var cfg = RTCAudioSessionConfiguration.webRTC()
        cfg.category = AVAudioSession.Category.playAndRecord.rawValue
        cfg.mode = AVAudioSession.Mode.voiceChat.rawValue
        cfg.categoryOptions = [.mixWithOthers, .defaultToSpeaker, .allowBluetooth, .allowBluetoothA2DP]
        try? rtc.setConfiguration(cfg)
        try? rtc.setActive(true)
        print("ğŸ” AudioSession reconfigured (isCaptured=\(isScreenCaptured))")
    }

    private func waitForIceGatheringComplete(using pc: RTCPeerConnection, timeout: TimeInterval) async throws {
        let start = Date()
        while pc.iceGatheringState != .complete {
            try await Task.sleep(nanoseconds: 200_000_000) // 0.2s
            if Date().timeIntervalSince(start) > timeout {
                throw NSError(domain: "ICE", code: -100,
                              userInfo: [NSLocalizedDescriptionKey: "ICE gathering timeout"])
            }
        }
    }

    // MARK: - Stats Metering
    private func startStatsMetering(on pc: RTCPeerConnection) {
        stopStatsMetering()
        statsTimer = Timer.scheduledTimer(withTimeInterval: 0.12, repeats: true) { [weak self, weak pc] _ in
            guard let self, let pc else { return }

            pc.statistics { report in
                var inboundLevel: Double = 0.0
                var outboundLevel: Double = 0.0

                for (_, stat) in report.statistics {
                    let type = stat.type
                    guard let members = stat.values as? [String: Any] else { continue }

                    if type == "inbound-rtp" {
                        if let lvl = members["audioLevel"] as? Double {
                            inboundLevel = max(inboundLevel, lvl)
                        } else if let lvlNum = members["audioLevel"] as? NSNumber {
                            inboundLevel = max(inboundLevel, lvlNum.doubleValue)
                        }
                    }

                    if type == "outbound-rtp" {
                        if let lvl = members["audioLevel"] as? Double {
                            outboundLevel = max(outboundLevel, lvl)
                        } else if let lvlNum = members["audioLevel"] as? NSNumber {
                            outboundLevel = max(outboundLevel, lvlNum.doubleValue)
                        }
                    }
                }

                self.emaInbound  = self.emaAlpha * inboundLevel  + (1 - self.emaAlpha) * self.emaInbound
                self.emaOutbound = self.emaAlpha * outboundLevel + (1 - self.emaAlpha) * self.emaOutbound

                let activeLevel = max(self.emaInbound, self.emaOutbound)

                DispatchQueue.main.async {
                    if activeLevel > self.silenceThreshold {
                        self.applyLevelToBands(activeLevel)
                    } else {
                        self.fadeBandsToSilence(step: 0.15)
                    }
                }
            }
        }
    }

    private func stopStatsMetering() {
        statsTimer?.invalidate()
        statsTimer = nil
        emaInbound = 0
        emaOutbound = 0
    }

    private func applyLevelToBands(_ level: Double) {
        let clamped = max(0.0, min(1.0, level))
        var newBands: [CGFloat] = []
        newBands.reserveCapacity(20)

        for i in 0..<20 {
            let centerBoost = 1.0 - abs(Double(i) - 9.5) / 9.5
            let jitter = (Double.random(in: -0.08...0.08))
            let v = max(0.0, min(1.0, clamped * (0.65 + 0.45 * centerBoost) + jitter))
            newBands.append(CGFloat(v))
        }
        self.bands = newBands
    }

    private func fadeBandsToSilence(step: CGFloat) {
        let new = bands.map { max(0.05, $0 - step * 0.2) }
        self.bands = new
    }

    private func resetBandsToSilence() {
        self.bands = Array(repeating: 0.05, count: 20)
    }
}

// MARK: - RTCPeerConnectionDelegate
extension RealtimeVoiceViewModel: RTCPeerConnectionDelegate {
    func peerConnection(_ peerConnection: RTCPeerConnection,
                        didChange stateChanged: RTCSignalingState) {
        print("ğŸ“¡ Signaling:", stateChanged.rawValue)
    }

    func peerConnectionShouldNegotiate(_ peerConnection: RTCPeerConnection) {
        print("ğŸ¤ Should negotiate")
    }

    func peerConnection(_ peerConnection: RTCPeerConnection,
                        didChange newState: RTCIceConnectionState) {
        print("ğŸ”— ICE Conn State:", newState.rawValue)
        if newState == .disconnected || newState == .failed || newState == .closed {
            DispatchQueue.main.async { self.isConnected = false }
        }
    }

    func peerConnection(_ peerConnection: RTCPeerConnection,
                        didChange newState: RTCIceGatheringState) {
        print("ğŸ§Š ICE Gathering:", newState.rawValue)
    }

    func peerConnection(_ peerConnection: RTCPeerConnection,
                        didGenerate candidate: RTCIceCandidate) {
        print("â• ICE candidate generated")
    }

    func peerConnection(_ peerConnection: RTCPeerConnection,
                        didRemove candidates: [RTCIceCandidate]) {
        print("â– ICE candidates removed:", candidates.count)
    }

    func peerConnection(_ peerConnection: RTCPeerConnection,
                        didOpen dataChannel: RTCDataChannel) {
        print("ğŸ“¨ DataChannel opened:", dataChannel.label)
    }

    func peerConnection(_ peerConnection: RTCPeerConnection,
                        didAdd stream: RTCMediaStream) {
        print("ğŸ“¥ Legacy: didAdd stream:", stream.streamId)
    }

    func peerConnection(_ peerConnection: RTCPeerConnection,
                        didRemove stream: RTCMediaStream) {
        print("ğŸ§¹ Legacy: didRemove stream:", stream.streamId)
    }

    func peerConnection(_ peerConnection: RTCPeerConnection,
                        didAdd rtpReceiver: RTCRtpReceiver,
                        streams: [RTCMediaStream]) {
        if rtpReceiver.track is RTCAudioTrack {
            print("ğŸ”Š Remote audio track (Unified Plan):", rtpReceiver.track?.trackId ?? "-")
        }
    }
}

// MARK: - RTCDataChannelDelegate
extension RealtimeVoiceViewModel: RTCDataChannelDelegate {
    func dataChannelDidChangeState(_ dataChannel: RTCDataChannel) {
        print("ğŸ§µ DataChannel '\(dataChannel.label)' state: \(dataChannel.readyState.rawValue)")
        
        guard dataChannel.readyState == .open, dataChannel.label == "oai-events" else { return }
        
        // âœ… FIXED: Ø¥Ù„ØºØ§Ø¡ Ø§Ù„Ù€ greeting Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ - Ø§Ù„Ø¢Ù† Ø§Ù„Ù€ AI Ø±Ø­ ÙŠØ±Ø¯ Ø·Ø¨ÙŠØ¹ÙŠ Ø£ÙˆÙ„ Ù…Ø§ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… ÙŠØ­ÙƒÙŠ
        // Ø§Ù„Ù€ greeting Ù…Ø­Ø¯Ø¯ ÙÙŠ Ø§Ù„Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆ Ø¹Ù„Ù‰ Ø§Ù„Ø³ÙŠØ±ÙØ± ÙˆØ¨ÙŠØ´ØªØºÙ„ ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹
        // Ù‡Ø°Ø§ ÙŠØ­Ø³Ù‘Ù† Ø§Ù„Ø«Ø¨Ø§Øª Ù„Ø£Ù†Ù‡ Ù…Ø§ ÙÙŠØ´ conflict Ø¨ÙŠÙ† ØªØ¹Ù„ÙŠÙ…Ø§Øª Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ ÙˆØ§Ù„Ø³ÙŠØ±ÙØ±
        
        print("âœ… DataChannel ready - waiting for user to speak")
        
        // ===========================================
        // OPTIONAL: Ù„Ùˆ Ø¨Ø¯Ùƒ auto-greeting (Ø¨Ø¯ÙˆÙ† conflict)
        // ===========================================
        // Uncomment the code below if you want automatic greeting:
        /*
        let payload: [String: Any] = [
            "type": "response.create",
            "response": [
                "modalities": ["audio", "text"]
                // âš ï¸ Ø¨Ø¯ÙˆÙ† "instructions" Ùˆ Ø¨Ø¯ÙˆÙ† "conversation": "none"
                // Ù‡Ø°Ø§ Ø¨ÙŠØ­ÙÙ‘Ø² Ø§Ù„Ù€ AI ÙŠØ±Ø¯ØŒ Ø¨Ø³ Ø¨ÙŠØ§Ø®Ø° Ø§Ù„ØªØ¹Ù„ÙŠÙ…Ø§Øª Ù…Ù† Ø§Ù„Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ
            ]
        ]

        if let data = try? JSONSerialization.data(withJSONObject: payload, options: []) {
            DispatchQueue.main.asyncAfter(deadline: .now() + 0.5) {
                let buf = RTCDataBuffer(data: data, isBinary: false)
                dataChannel.sendData(buf)
                print("ğŸš€ Triggered AI greeting (using server scenario)")
            }
        }
        */
    }

    func dataChannel(_ dataChannel: RTCDataChannel, didReceiveMessageWith buffer: RTCDataBuffer) {
        if !buffer.isBinary, let txt = String(data: buffer.data, encoding: .utf8) {
            // Print response in requested format
            print("\n===========> RESPONSE")
            print(txt)
            print("===========> END RESPONSE\n")
            
            // Log only if contains interesting data
            if txt.contains("function") || txt.contains("page") || txt.contains("navigation") {
                print("ğŸ” FOUND FUNCTION/PAGE/Navigation in message!")
            }
            
            // âœ… ØªØ­Ù‚Ù‚ Ø¥Ø°Ø§ ÙƒØ§Ù† navigation event Ù…Ø¨Ø§Ø´Ø±
            if let data = txt.data(using: .utf8),
               let json = try? JSONSerialization.jsonObject(with: data) as? [String: Any] {
                
                // Ø§Ø³ØªØ®Ø±Ø¬ text Ù…Ù† response.text.done
                if let responseText = json["text"] as? String {
                    print("ğŸ“ AI text response: \(responseText)")
                    print("ğŸ” Calling extractNavigationFromText...")
                    // Ø§Ø¨Ø­Ø« Ø¹Ù† navigation command ÙÙŠ Ø§Ù„Ù†Øµ
                    if let result = extractNavigationFromText(responseText) {
                        print("âœ… Found navigation in text: \(result)")
                        print("ğŸ¯ Setting navigationTarget to: \(result.page)")
                        DispatchQueue.main.async {
                            print("ğŸ“± INSIDE MAIN THREAD - Setting navigationTarget")
                            self.navigationTarget = result.page
                            self.cliqAmount = result.amount
                            self.cliqPhoneNumber = result.phone
                            print("ğŸ“± navigationTarget value after set: \(self.navigationTarget ?? "nil")")
                        }
                        return
                    } else {
                        print("âŒ extractNavigationFromText returned nil")
                    }
                }
                
                // âœ… Handle function call arguments (delta - Ø¬Ù…Ø¹ Ø§Ù„Ù‚Ø·Ø¹)
                if let type = json["type"] as? String,
                   type == "response.function_call_arguments.delta",
                   let callId = json["call_id"] as? String,
                   let delta = json["delta"] as? String {
                    print("ğŸ“ Collecting function call args for \(callId): \(delta)")
                    if pendingFunctionCallArgs[callId] == nil {
                        pendingFunctionCallArgs[callId] = ""
                    }
                    pendingFunctionCallArgs[callId] = (pendingFunctionCallArgs[callId] ?? "") + delta
                    print("ğŸ“¦ Total args for \(callId): \(pendingFunctionCallArgs[callId] ?? "")")
                    return
                }
                
                // âœ… Handle audio transcript done - extract JSON from transcript
                if let type = json["type"] as? String,
                   type == "response.audio_transcript.done",
                   let transcript = json["transcript"] as? String {
                    print("ğŸ“ Audio transcript done: \(transcript)")
                    // Ø§Ø¨Ø­Ø« Ø¹Ù† JSON navigation command ÙÙŠ Ø§Ù„Ù€ transcript
                    if let result = extractNavigationFromText(transcript) {
                        print("âœ… Found navigation in transcript: page=\(result.page), amount=\(result.amount ?? "nil"), phone=\(result.phone ?? "nil"), alias=\(result.alias ?? "nil")")
                        DispatchQueue.main.async {
                            self.navigationTarget = result.page
                            self.pendingNavigation = result.page
                            self.cliqAmount = result.amount
                            self.cliqPhoneNumber = result.phone
                            self.cliqAlias = result.alias
                            print("âœ… Set navigation data")
                        }
                    }
                    return
                }
                
                // âœ… Handle completed function call
                if let type = json["type"] as? String,
                   type == "response.function_call_arguments.done",
                   let callId = json["call_id"] as? String,
                   let functionName = json["name"] as? String {
                    print("ğŸ¯ Function call completed: \(functionName), callId: \(callId)")
                    if let arguments = pendingFunctionCallArgs[callId] {
                        print("ğŸ“¦ Full arguments: \(arguments)")
                        if let argsData = arguments.data(using: .utf8),
                           let argsJson = try? JSONSerialization.jsonObject(with: argsData) as? [String: Any] {
                            print("âœ… Parsed args JSON: \(argsJson)")
                            if let page = argsJson["page"] as? String {
                                print("ğŸ¯ Found function call \(functionName): \(page)")
                                // Force main thread update
                                DispatchQueue.main.async {
                                    // Set navigationTarget Ùˆ pendingNavigation Ù…Ø¹Ø§Ù‹ Ù„Ù„Ø¶Ù…Ø§Ù†
                                    self.navigationTarget = page
                                    self.pendingNavigation = page
                                    print("âœ… Set navigationTarget and pendingNavigation: \(page)")
                                }
                            } else {
                                print("âŒ No 'page' key in args")
                            }
                        } else {
                            print("âŒ Failed to parse args JSON")
                        }
                    } else {
                        print("âŒ No pending args for \(callId)")
                    }
                    pendingFunctionCallArgs.removeValue(forKey: callId)
                    return
                }
                
                // âœ… Handle function call from output_item (legacy fallback)
                if let type = json["type"] as? String,
                   type == "response.output_item.added" || type == "response.output_item.done",
                   let item = json["item"] as? [String: Any],
                   let itemType = item["type"] as? String,
                   itemType == "function_call",
                   let functionName = item["name"] as? String,
                   functionName == "redirect_to_page",
                   let arguments = item["arguments"] as? String,
                   let argsData = arguments.data(using: .utf8),
                   let argsJson = try? JSONSerialization.jsonObject(with: argsData) as? [String: Any],
                   let page = argsJson["page"] as? String {
                    print("ğŸ¯ Found function call redirect_to_page (legacy): \(page)")
                    DispatchQueue.main.async {
                        self.navigationTarget = page
                    }
                    return
                }
                
                // ØªØ­Ù‚Ù‚ Ø¥Ø°Ø§ ÙƒØ§Ù† navigation event Ù…Ø¨Ø§Ø´Ø±
                if let type = json["type"] as? String, type == "navigation",
                   let page = json["page"] as? String {
                    print("ğŸ¯ Navigation received: \(page)")
                    DispatchQueue.main.async {
                        self.navigationTarget = page
                    }
                    return
                }
            }
            
            // âœ… Ø¨Ø­Ø« ÙØ´Ù„ØŒ Ø­Ø§ÙˆÙ„ extract Ù…Ù† Ø§Ù„Ù€ raw text
            if txt.contains("\"page\"") {
                print("ğŸ” Searching for navigation JSON in raw text...")
                if let result = extractNavigationFromText(txt) {
                    print("âœ… Found navigation command: \(result)")
                    DispatchQueue.main.async {
                        self.navigationTarget = result.page
                        self.cliqAmount = result.amount
                        self.cliqPhoneNumber = result.phone
                        self.cliqAlias = result.alias
                    }
                }
            }
        }
    }
    
    private func extractNavigationFromText(_ text: String) -> CliQTransferData? {
        print("ğŸ”§ extractNavigationFromText called with: '\(text)'")
        // Handle multiline JSON and normalize all whitespace
        let cleaned = text.replacingOccurrences(of: "\n", with: " ")
            .replacingOccurrences(of: "\r", with: " ")
            .replacingOccurrences(of: "\t", with: " ")
            // Replace multiple spaces with single space
            .components(separatedBy: .whitespaces).filter { !$0.isEmpty }.joined(separator: " ")
        print("ğŸ”§ After cleaning: '\(cleaned)'")
        
        // Try to extract full JSON object
        if let jsonRange = cleaned.range(of: "{\"") {
            let after = String(cleaned[jsonRange.lowerBound...])
            if let jsonEnd = after.range(of: "}") {
                let jsonString = String(after[..<jsonEnd.upperBound])
                print("ğŸ” Found JSON: '\(jsonString)'")
                
                if let jsonData = jsonString.data(using: .utf8),
                   let json = try? JSONSerialization.jsonObject(with: jsonData) as? [String: Any] {
                    let page = json["page"] as? String ?? ""
                    let amount = json["amount"] as? String
                    let phone = json["phone"] as? String
                    let alias = json["alias"] as? String
                    
                    print("âœ… Extracted: page=\(page), amount=\(amount ?? "nil"), phone=\(phone ?? "nil"), alias=\(alias ?? "nil")")
                    return CliQTransferData(page: page, amount: amount, phone: phone, alias: alias)
                }
            }
        }
        
        // Fallback: Try simple pattern matching - flexible spacing after colon
        if let pageRange = cleaned.range(of: "\"page\"") {
            let afterPage = String(cleaned[pageRange.upperBound...])
            if let colonRange = afterPage.range(of: ":"),
               let firstQuote = afterPage.range(of: "\"", range: colonRange.upperBound..<afterPage.endIndex) {
                let afterQuote = afterPage[firstQuote.upperBound...]
                if let secondQuote = afterQuote.range(of: "\"") {
                    let pageName = String(afterQuote[..<secondQuote.lowerBound]).trimmingCharacters(in: .whitespaces)
                    print("ğŸ“± Extracted page name (flexible): '\(pageName)'")
                    return CliQTransferData(page: pageName, amount: nil, phone: nil)
                }
            }
        }
        
        print("âŒ Could not extract JSON from text")
        return nil
    }
}

/*
 ===========================================
 ğŸ“ Ù…Ù„Ø§Ø­Ø¸Ø§Øª Ù…Ù‡Ù…Ø©:
 ===========================================
 
 1. Ø§Ù„ØªØ¹Ø¯ÙŠÙ„ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ: Ø¥Ù„ØºØ§Ø¡ Ø§Ù„Ù€ greeting Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ ÙÙŠ dataChannelDidChangeState
    - Ù‡Ø°Ø§ ÙŠØ­Ù„ Ù…Ø´ÙƒÙ„Ø© conflict Ø¨ÙŠÙ† ØªØ¹Ù„ÙŠÙ…Ø§Øª Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ ÙˆØ§Ù„Ø³ÙŠØ±ÙØ±
    - Ø§Ù„Ù†ØªÙŠØ¬Ø©: Ù†Ø¨Ø±Ø© ÙˆÙ†Ø·Ù‚ Ø£ÙƒØ«Ø± Ø«Ø¨Ø§ØªØ§Ù‹
 
 2. Ø§Ù„Ù€ greeting Ø§Ù„Ø¢Ù† Ù…Ø­Ø¯Ø¯ ÙÙŠ Ø§Ù„Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆ Ø¹Ù„Ù‰ Ø§Ù„Ø³ÙŠØ±ÙØ±:
    - "Ù…Ø±Ø­Ø¨Ù‹Ø§ Ø£ÙØ³ØªØ§Ø° ØºÙŠØ«. Ù…Ø¹Ùƒ Ø£Ù…Ø¬Ø¯ Ù…Ù† Ø§Ù„Ø¨Ù†Ùƒ Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠ..."
    - ÙŠØ´ØªØºÙ„ ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹ Ø£ÙˆÙ„ Ù…Ø§ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… ÙŠØ­ÙƒÙŠ
 
 3. Ù„Ùˆ Ø¨Ø¯Ùƒ auto-greeting:
    - Uncomment Ø§Ù„ÙƒÙˆØ¯ ÙÙŠ dataChannelDidChangeState
    - Ø¨Ø³ ØªØ£ÙƒØ¯ Ø¥Ù†Ù‡ Ø¨Ø¯ÙˆÙ† "instructions" Ùˆ "conversation": "none"
 
 4. Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø§Ù„Ù…ØªÙˆÙ‚Ø¹Ø©:
    - âœ… Ù†Ø¨Ø±Ø© Ø£ÙƒØ«Ø± Ø«Ø¨Ø§ØªØ§Ù‹
    - âœ… Ù†Ø·Ù‚ Ø£ÙˆØ¶Ø­ (14 ÙƒÙ„Ù…Ø© Ù…Ø­ÙÙˆØ¸Ø© ÙÙŠ Ø§Ù„Ø³ÙŠØ±ÙØ±)
    - âœ… Ø±Ø¯ÙˆØ¯ Ù…ØªØ³Ù‚Ø©
    - âœ… Ø£Ù‚Ù„ ØªØ´ØªØª
 
 ===========================================
 */
